#!/usr/bin/env python3

import argparse
import json
import os
import shutil
import tempfile


class Result:
    def __init__(self, name, parameter, version, throughput):
        self.name = name
        self.parameter = parameter
        self.version = version
        self.throughput = throughput
        self.increase = None

    @classmethod
    def from_json(cls, json, version):
        return cls(json["benchmark"], json["params"]["value"], version, json["primaryMetric"]["score"])

    def set_increase(self, other):
        if other is not None and self.name == other.name and self.parameter == other.parameter:
            self.increase = ((self.throughput - other.throughput) / other.throughput) * 100.0


BENCHMARKS = {"Iban", "Bic", "CreditorIdentifier", "Calendar"}
VERSIONS = {
    "2.1.0": {
        "benchmarks": {"Iban", "Bic", "CreditorIdentifier"}
    },
    "3.4.0": {
        "benchmarks": {"Iban", "Bic", "CreditorIdentifier", "Calendar"}
    },
    "4.0.0-SNAPSHOT": {
        "benchmarks": {"Iban", "Bic", "CreditorIdentifier", "Calendar"}
    }
}

project_dir = os.path.dirname(__file__)
source_dir = project_dir + '/src/main/java/b'
exclusion_dir = project_dir + '/src'

os.chdir(project_dir)
parser = argparse.ArgumentParser(description="Run jbanking benchmarks")
parser.add_argument("-f", "--fast", action="store_true",
                    help="activate fast run mode (for test purpose only)")
parser.add_argument("-v", "--version", type=str, nargs="*",
                    help="limit to only some versions")
parser.add_argument("-e", "--exclude", type=str, nargs="*",
                    help="exclude some benchmarks (must be on of " + ", ".join(BENCHMARKS) + ")")
args = parser.parse_args()

versions = set(args.version) if args.version else set(VERSIONS.keys())
iteration = 1 if args.fast else 3
warmup_iteration = 0 if args.fast else 3
time = 1 if args.fast else 10
globalExclusions = set(args.exclude) if args.exclude else set()


def exclude_benchmarks(benchmarks):
    for benchmark in benchmarks:
        class_file = source_dir + '/' + benchmark + 'Benchmark.java'
        shutil.move(class_file, exclusion_dir)


def restore_benchmarks(benchmarks):
    for benchmark in benchmarks:
        class_file = exclusion_dir + '/' + benchmark + 'Benchmark.java'
        shutil.move(class_file, source_dir)


def execute(command):
    failed = os.system(command)
    if failed:
        exit(1)


base_dir = tempfile.mkdtemp(prefix="jbanking-benchmarks.", dir="/tmp")
for version in sorted(versions):
    excludedBenchmarks = BENCHMARKS.difference(
        VERSIONS[version]['benchmarks']).union(globalExclusions)

    exclude_benchmarks(excludedBenchmarks)
    maven_args = "--offline" if version.__contains__("SNAPSHOT") else ""
    execute(
        "mvn clean package {args} -Djbanking.version={version}"
        .format(version=version, args=maven_args)
    )
    restore_benchmarks(excludedBenchmarks)

    version_dir = base_dir + "/" + version
    version_jar = "jbanking-benchmarks-{version}.jar".format(version=version)

    os.mkdir(version_dir)
    shutil.move("target/" + version_jar, version_dir)
    shutil.copy(".tool-versions", version_dir)

    os.chdir(version_dir)
    execute(
        "java -jar {jar} -prof jfr -f 1 -bm Throughput -foe true -i {i} -wi {wi} -r {r} -w {w} -rf JSON -rff {rff} -jvmArgs -Xms128m -jvmArgs -Xmx128m"
        .format(jar=version_jar, i=iteration, wi=warmup_iteration, r=time, w=time, rff="jbanking-benchmarks.json")
    )

    os.chdir(project_dir)

results = []
for version in sorted(versions):
    with open("{dir}/{version}/jbanking-benchmarks.json".format(dir=base_dir, version=version), "r") as json_file:
        version_results = json.load(json_file)
        for version_result in version_results:
            results.append(Result.from_json(version_result, version))
results.sort(key=lambda r: (r.name, r.parameter, r.throughput))

previous = None
for current in results:
    current.set_increase(previous)
    previous = current


with open("{dir}/jbanking-benchmarks.md".format(dir=base_dir), "w") as f:
    f.writelines([
        "| Name | Parameter | Version | Ops/s | Increase |\n",
        "| ---- | --------- | ------- | ----- | -------- |\n"
    ])

    for current in results:
        f.writelines([
            "| {n} | {p} | {v} | {t} | {i} |\n"
            .format(n=current.name, p=current.parameter, v=current.version,
                    t="{:,.0f}".format(current.throughput),
                    i='N/A' if current.increase is None else "{:,.2f}%".format(current.increase))
        ])

print("Benchmark finished, results can be found in " + base_dir)
